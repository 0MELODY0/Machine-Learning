{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vgg_model(path):\n",
    "    \"\"\"\n",
    "    Here is the detailed configuration of the VGG model:\n",
    "        0 is conv1_1 (3, 3, 3, 64)\n",
    "        1 is relu\n",
    "        2 is conv1_2 (3, 3, 64, 64)\n",
    "        3 is relu    \n",
    "        4 is maxpool\n",
    "        5 is conv2_1 (3, 3, 64, 128)\n",
    "        6 is relu\n",
    "        7 is conv2_2 (3, 3, 128, 128)\n",
    "        8 is relu\n",
    "        9 is maxpool\n",
    "        10 is conv3_1 (3, 3, 128, 256)\n",
    "        11 is relu\n",
    "        12 is conv3_2 (3, 3, 256, 256)\n",
    "        13 is relu\n",
    "        14 is conv3_3 (3, 3, 256, 256)\n",
    "        15 is relu\n",
    "        16 is conv3_4 (3, 3, 256, 256)\n",
    "        17 is relu\n",
    "        18 is maxpool\n",
    "        19 is conv4_1 (3, 3, 256, 512)\n",
    "        20 is relu\n",
    "        21 is conv4_2 (3, 3, 512, 512)\n",
    "        22 is relu\n",
    "        23 is conv4_3 (3, 3, 512, 512)\n",
    "        24 is relu\n",
    "        25 is conv4_4 (3, 3, 512, 512)\n",
    "        26 is relu\n",
    "        27 is maxpool\n",
    "        28 is conv5_1 (3, 3, 512, 512)\n",
    "        29 is relu\n",
    "        30 is conv5_2 (3, 3, 512, 512)\n",
    "        31 is relu\n",
    "        32 is conv5_3 (3, 3, 512, 512)\n",
    "        33 is relu\n",
    "        34 is conv5_4 (3, 3, 512, 512)\n",
    "        35 is relu\n",
    "        36 is maxpool\n",
    "        37 is fullyconnected (7, 7, 512, 4096)\n",
    "        38 is relu\n",
    "        39 is fullyconnected (1, 1, 4096, 4096)\n",
    "        40 is relu\n",
    "        41 is fullyconnected (1, 1, 4096, 1000)\n",
    "        42 is softmax\n",
    "    \"\"\"\n",
    "    \n",
    "    vgg = scipy.io.loadmat(path)\n",
    "\n",
    "    vgg_layers = vgg['layers']\n",
    "    \n",
    "    def _weights(layer, expected_layer_name):\n",
    "     \n",
    "        wb = vgg_layers[0][layer][0][0][2]\n",
    "        W = wb[0][0]\n",
    "        b = wb[0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b\n",
    "\n",
    "        return W, b\n",
    "\n",
    "    def _relu(conv2d_layer):\n",
    "   \n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "  \n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "\n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "      \n",
    "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
    "\n",
    "    def _avgpool(prev_layer):\n",
    "      \n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Constructs the graph model.\n",
    "    graph = {}\n",
    "    graph['input']   = tf.Variable(np.zeros((1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)), dtype = 'float32')\n",
    "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    \n",
    "    IMAGE_WIDTH = 300\n",
    "    IMAGE_HEIGHT = 225\n",
    "    COLOR_CHANNELS = 3\n",
    "    NOISE_RATIO = 0.6\n",
    "    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3)) \n",
    "    \n",
    "def generate_noise_image(content_image, noise_ratio = CONFIG.NOISE_RATIO):\n",
    "    \n",
    "    noise_image = np.random.uniform(-20, 20, (1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)).astype('float32')\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    \n",
    "    return input_image\n",
    "\n",
    "def reshape_and_normalize_image(image):\n",
    "\n",
    "    image = np.reshape(image, ((1,) + image.shape))\n",
    "    image = image - CONFIG.MEANS\n",
    "    \n",
    "    return image\n",
    "\n",
    "def save_image(path, image):\n",
    "    \n",
    "    image = image + CONFIG.MEANS\n",
    "    image = np.clip(image[0], 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_content_cost(a_C, a_G):\n",
    "\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    a_C_unrolled = tf.transpose(tf.reshape(a_C, [ n_H * n_W, n_C]))\n",
    "    a_G_unrolled = tf.transpose(tf.reshape(a_G, [ n_H * n_W, n_C]))\n",
    "    \n",
    "    J_content = tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled))) /  (4 * n_H * n_W * n_C)\n",
    "    \n",
    "    return J_content\n",
    "\n",
    "def gram_matrix(A):\n",
    "\n",
    "    GA = tf.matmul(A, tf.transpose(A))\n",
    "    \n",
    "    return GA\n",
    "\n",
    "def compute_layer_style_cost(a_S, a_G):\n",
    "\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    a_S = tf.transpose(tf.reshape(a_S, [n_H * n_W, n_C]))\n",
    "    a_G = tf.transpose(tf.reshape(a_G, [n_H * n_W, n_C]))\n",
    "\n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "\n",
    "    J_style_layer = tf.reduce_sum(tf.square(tf.subtract(GS, GG))) / (4 * tf.square(tf.to_float(n_H * n_W * n_C)))\n",
    "    \n",
    "    return J_style_layer\n",
    "\n",
    "def compute_style_cost(model, STYLE_LAYERS):\n",
    "    \n",
    "    J_style = 0\n",
    "\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "\n",
    "        out = model[layer_name]\n",
    "        \n",
    "        a_S = sess.run(out)\n",
    "        a_G = out\n",
    "        \n",
    "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
    "        J_style += coeff * J_style_layer\n",
    "\n",
    "    return J_style\n",
    "\n",
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "    \n",
    "    J = alpha * J_content + beta * J_style\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_nn(sess, input_image, num_iterations = 200):\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model['input'].assign(input_image))\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        sess.run(train_step)\n",
    "\n",
    "        generated_image = sess.run(model['input'])\n",
    "\n",
    "        if i%20 == 0:\n",
    "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"total cost = \" + str(Jt))\n",
    "            print(\"content cost = \" + str(Jc))\n",
    "            print(\"style cost = \" + str(Js))\n",
    "\n",
    "            save_image(\"out/style/\" + str(i) + \".png\", generated_image)\n",
    "    \n",
    "    save_image('out/style/generated_image.jpg', generated_image)\n",
    "    \n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2)]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "content_image = scipy.misc.imread(\"images/content300.jpg\")\n",
    "content_image = reshape_and_normalize_image(content_image)\n",
    "\n",
    "style_image = scipy.misc.imread(\"images/stone_style.jpg\")\n",
    "style_image = reshape_and_normalize_image(style_image)\n",
    "\n",
    "generated_image = generate_noise_image(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_vgg_model(\"model_data/imagenet-vgg-verydeep-19.mat\")\n",
    "\n",
    "sess.run(model['input'].assign(content_image))\n",
    "\n",
    "out = model['conv4_2']\n",
    "a_C = sess.run(out)\n",
    "a_G = out\n",
    "\n",
    "J_content = compute_content_cost(a_C, a_G)\n",
    "sess.run(model['input'].assign(style_image))\n",
    "J_style = compute_style_cost(model, STYLE_LAYERS)\n",
    "J = total_cost(J_content, J_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :\n",
      "total cost = 3.45525e+09\n",
      "content cost = 12157.7\n",
      "style cost = 8.63783e+07\n",
      "Iteration 20 :\n",
      "total cost = 2.37871e+08\n",
      "content cost = 18937.9\n",
      "style cost = 5.94205e+06\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "train_step = optimizer.minimize(J)\n",
    "model_nn(sess, generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
