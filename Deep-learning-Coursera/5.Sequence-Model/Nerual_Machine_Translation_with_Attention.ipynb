{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "fake.seed(12345)\n",
    "random.seed(12345)\n",
    "\n",
    "EXAMPLES = ['3 May 1979', '5 Apr 09', '20th February 2016', 'Wed 10 Jul 2007']\n",
    "\n",
    "# Define format of the data we would like to generate\n",
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'd MMM YYY', \n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY']\n",
    "\n",
    "# change this if you want it to work with another language\n",
    "LOCALES = ['en_US']\n",
    "\n",
    "def load_date():\n",
    "    \"\"\"\n",
    "        Loads some fake dates \n",
    "        :returns: tuple containing human readable string, machine readable string, and date object\n",
    "    \"\"\"\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    try:\n",
    "        human_readable = format_date(dt, format=random.choice(FORMATS),  locale='en_US') # locale=random.choice(LOCALES))\n",
    "        human_readable = human_readable.lower()\n",
    "        human_readable = human_readable.replace(',','')\n",
    "        machine_readable = dt.isoformat()\n",
    "        \n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human_readable, machine_readable, dt\n",
    "\n",
    "def load_dataset(m):\n",
    "    \"\"\"\n",
    "        Loads a dataset with m examples and vocabularies\n",
    "        :m: the number of examples to generate\n",
    "    \"\"\"\n",
    "    \n",
    "    human_vocab = set()\n",
    "    machine_vocab = set()\n",
    "    dataset = []\n",
    "    Tx = 30\n",
    "    \n",
    "\n",
    "    for i in tqdm(range(m)):\n",
    "        h, m, _ = load_date()\n",
    "        if h is not None:\n",
    "            dataset.append((h, m))\n",
    "            human_vocab.update(tuple(h))\n",
    "            machine_vocab.update(tuple(m))\n",
    "    \n",
    "    human = dict(zip(sorted(human_vocab) + ['<unk>', '<pad>'], \n",
    "                     list(range(len(human_vocab) + 2))))\n",
    "    inv_machine = dict(enumerate(sorted(machine_vocab)))\n",
    "    machine = {v:k for k,v in inv_machine.items()}\n",
    " \n",
    "    return dataset, human, machine, inv_machine\n",
    "\n",
    "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
    "    \n",
    "    X, Y = zip(*dataset)\n",
    "    \n",
    "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
    "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
    "    \n",
    "    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
    "    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
    "\n",
    "    return X, np.array(Y), Xoh, Yoh\n",
    "\n",
    "def string_to_int(string, length, vocab):\n",
    "    \"\"\"\n",
    "    Converts all strings in the vocabulary into a list of integers representing the positions of the\n",
    "    input string's characters in the \"vocab\"\n",
    "    \n",
    "    Arguments:\n",
    "    string -- input string, e.g. 'Wed 10 Jul 2007'\n",
    "    length -- the number of time steps you'd like, determines if the output will be padded or cut\n",
    "    vocab -- vocabulary, dictionary used to index every character of your \"string\"\n",
    "    \n",
    "    Returns:\n",
    "    rep -- list of integers (or '<unk>') (size = length) representing the position of the string's character in the vocabulary\n",
    "    \"\"\"\n",
    "    \n",
    "    #make lower to standardize\n",
    "    string = string.lower()\n",
    "    string = string.replace(',','')\n",
    "    \n",
    "    if len(string) > length:\n",
    "        string = string[:length]\n",
    "        \n",
    "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
    "    \n",
    "    if len(string) < length:\n",
    "        rep += [vocab['<pad>']] * (length - len(string))\n",
    "    \n",
    "    #print (rep)\n",
    "    return rep\n",
    "\n",
    "\n",
    "def int_to_string(ints, inv_vocab):\n",
    "    \"\"\"\n",
    "    Output a machine readable list of characters based on a list of indexes in the machine's vocabulary\n",
    "    \n",
    "    Arguments:\n",
    "    ints -- list of integers representing indexes in the machine's vocabulary\n",
    "    inv_vocab -- dictionary mapping machine readable indexes to machine readable characters \n",
    "    \n",
    "    Returns:\n",
    "    l -- list of characters corresponding to the indexes of ints thanks to the inv_vocab mapping\n",
    "    \"\"\"\n",
    "    \n",
    "    l = [inv_vocab[i] for i in ints]\n",
    "    return l\n",
    "\n",
    "def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n",
    "    encoded = string_to_int(text, TIME_STEPS, input_vocabulary)\n",
    "    prediction = model.predict(np.array([encoded]))\n",
    "    prediction = np.argmax(prediction[0], axis=-1)\n",
    "    return int_to_string(prediction, inv_output_vocabulary)\n",
    "\n",
    "def run_examples(model, input_vocabulary, inv_output_vocabulary, examples=EXAMPLES):\n",
    "    predicted = []\n",
    "    for example in examples:\n",
    "        predicted.append(''.join(run_example(model, input_vocabulary, inv_output_vocabulary, example)))\n",
    "        print('input:', example)\n",
    "        print('output:', predicted[-1])\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x : Tensor.\n",
    "        axis: Integer, axis along which the softmax normalization is applied.\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation.\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n",
    "        \n",
    "\n",
    "def plot_attention_map(model, input_vocabulary, inv_output_vocabulary, text, n_s = 128, num = 6, Tx = 30, Ty = 10):\n",
    "    \"\"\"\n",
    "    Plot the attention map.\n",
    "  \n",
    "    \"\"\"\n",
    "    attention_map = np.zeros((10, 30))\n",
    "    Ty, Tx = attention_map.shape\n",
    "    \n",
    "    s0 = np.zeros((1, n_s))\n",
    "    c0 = np.zeros((1, n_s))\n",
    "    layer = model.layers[num]\n",
    "\n",
    "    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 30))\n",
    "    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n",
    "\n",
    "    f = K.function(model.inputs, [layer.get_output_at(t) for t in range(Ty)])\n",
    "    r = f([encoded, s0, c0])\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        for t_prime in range(Tx):\n",
    "            attention_map[t][t_prime] = r[t][0,t_prime,0]\n",
    "\n",
    "    # Normalize attention map\n",
    "#     row_max = attention_map.max(axis=1)\n",
    "#     attention_map = attention_map / row_max[:, None]\n",
    "\n",
    "    prediction = model.predict([encoded, s0, c0])\n",
    "    \n",
    "    predicted_text = []\n",
    "    for i in range(len(prediction)):\n",
    "        predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n",
    "        \n",
    "    predicted_text = list(predicted_text)\n",
    "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
    "    text_ = list(text)\n",
    "    \n",
    "    # get the lengths of the string\n",
    "    input_length = len(text)\n",
    "    output_length = Ty\n",
    "    \n",
    "    # Plot the attention_map\n",
    "    plt.clf()\n",
    "    f = plt.figure(figsize=(8, 8.5))\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "    # add image\n",
    "    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "    # add colorbar\n",
    "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
    "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n",
    "\n",
    "    # add labels\n",
    "    ax.set_yticks(range(output_length))\n",
    "    ax.set_yticklabels(predicted_text[:output_length])\n",
    "\n",
    "    ax.set_xticks(range(input_length))\n",
    "    ax.set_xticklabels(text_[:input_length], rotation=45)\n",
    "\n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "\n",
    "    # add grid and legend\n",
    "    ax.grid()\n",
    "\n",
    "    #f.show()\n",
    "    \n",
    "    return attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 6164.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 9 may 1998\n",
      "Target date: 1998-05-09\n",
      "\n",
      "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
      "\n",
      "Source after preprocessing (one-hot): [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "Target after preprocessing (one-hot): [[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)\n",
    "\n",
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)\n",
    "\n",
    "def one_step_attention(a, s_prev):\n",
    "\n",
    "    s_prev = repeator(s_prev)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    e = densor1(concat)\n",
    "    energies = densor2(e)\n",
    "    alphas = activator(energies)\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_a = 32\n",
    "n_s = 64\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)\n",
    "\n",
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences = True))(X)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "    \n",
    "        context =  one_step_attention(a, s)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state = [s, c])\n",
    "        out = output_layer(s)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    model = Model(inputs = [X, s0, c0], outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       17920       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_4 (RepeatVector)  (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_4[9][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 30, 10)       1290        concatenate_4[0][0]              \n",
      "                                                                 concatenate_4[1][0]              \n",
      "                                                                 concatenate_4[2][0]              \n",
      "                                                                 concatenate_4[3][0]              \n",
      "                                                                 concatenate_4[4][0]              \n",
      "                                                                 concatenate_4[5][0]              \n",
      "                                                                 concatenate_4[6][0]              \n",
      "                                                                 concatenate_4[7][0]              \n",
      "                                                                 concatenate_4[8][0]              \n",
      "                                                                 concatenate_4[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30, 1)        11          dense_7[0][0]                    \n",
      "                                                                 dense_7[1][0]                    \n",
      "                                                                 dense_7[2][0]                    \n",
      "                                                                 dense_7[3][0]                    \n",
      "                                                                 dense_7[4][0]                    \n",
      "                                                                 dense_7[5][0]                    \n",
      "                                                                 dense_7[6][0]                    \n",
      "                                                                 dense_7[7][0]                    \n",
      "                                                                 dense_7[8][0]                    \n",
      "                                                                 dense_7[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_8[0][0]                    \n",
      "                                                                 dense_8[1][0]                    \n",
      "                                                                 dense_8[2][0]                    \n",
      "                                                                 dense_8[3][0]                    \n",
      "                                                                 dense_8[4][0]                    \n",
      "                                                                 dense_8[5][0]                    \n",
      "                                                                 dense_8[6][0]                    \n",
      "                                                                 dense_8[7][0]                    \n",
      "                                                                 dense_8[8][0]                    \n",
      "                                                                 dense_8[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 11)           715         lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1600/10000 [===>..........................] - ETA: 1:14:58 - loss: 24.0167 - dense_9_loss_1: 2.4043 - dense_9_loss_2: 2.3955 - dense_9_loss_3: 2.4053 - dense_9_loss_4: 2.3977 - dense_9_loss_5: 2.4027 - dense_9_loss_6: 2.4013 - dense_9_loss_7: 2.3972 - dense_9_loss_8: 2.4046 - dense_9_loss_9: 2.4135 - dense_9_loss_10: 2.3946 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.1100 - dense_9_acc_5: 0.0300 - dense_9_acc_6: 0.0000e+00 - dense_9_acc_7: 0.1200 - dense_9_acc_8: 0.0300 - dense_9_acc_9: 0.0000e+00 - dense_9_acc_10: 0.110 - ETA: 37:36 - loss: 23.8797 - dense_9_loss_1: 2.3972 - dense_9_loss_2: 2.3941 - dense_9_loss_3: 2.4027 - dense_9_loss_4: 2.4008 - dense_9_loss_5: 2.3564 - dense_9_loss_6: 2.3791 - dense_9_loss_7: 2.4008 - dense_9_loss_8: 2.3505 - dense_9_loss_9: 2.3960 - dense_9_loss_10: 2.4021 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.0550 - dense_9_acc_5: 0.5150 - dense_9_acc_6: 0.0000e+00 - dense_9_acc_7: 0.0600 - dense_9_acc_8: 0.5150 - dense_9_acc_9: 0.0000e+00 - dense_9_acc_10: 0.0550  - ETA: 25:07 - loss: 23.7408 - dense_9_loss_1: 2.3899 - dense_9_loss_2: 2.3918 - dense_9_loss_3: 2.3997 - dense_9_loss_4: 2.4045 - dense_9_loss_5: 2.3069 - dense_9_loss_6: 2.3562 - dense_9_loss_7: 2.4072 - dense_9_loss_8: 2.2928 - dense_9_loss_9: 2.3795 - dense_9_loss_10: 2.4124 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.0367 - dense_9_acc_5: 0.6767 - dense_9_acc_6: 0.0000e+00 - dense_9_acc_7: 0.0400 - dense_9_acc_8: 0.6767 - dense_9_acc_9: 0.0000e+00 - dense_9_acc_10: 0.036 - ETA: 18:53 - loss: 23.5590 - dense_9_loss_1: 2.3811 - dense_9_loss_2: 2.3891 - dense_9_loss_3: 2.3995 - dense_9_loss_4: 2.4109 - dense_9_loss_5: 2.2450 - dense_9_loss_6: 2.3245 - dense_9_loss_7: 2.4094 - dense_9_loss_8: 2.2181 - dense_9_loss_9: 2.3586 - dense_9_loss_10: 2.4228 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.0275 - dense_9_acc_5: 0.7575 - dense_9_acc_6: 0.0000e+00 - dense_9_acc_7: 0.0300 - dense_9_acc_8: 0.7575 - dense_9_acc_9: 0.0000e+00 - dense_9_acc_10: 0.027 - ETA: 15:09 - loss: 23.3471 - dense_9_loss_1: 2.3727 - dense_9_loss_2: 2.3829 - dense_9_loss_3: 2.3932 - dense_9_loss_4: 2.4235 - dense_9_loss_5: 2.1675 - dense_9_loss_6: 2.2862 - dense_9_loss_7: 2.4297 - dense_9_loss_8: 2.1197 - dense_9_loss_9: 2.3260 - dense_9_loss_10: 2.4456 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.0220 - dense_9_acc_5: 0.8060 - dense_9_acc_6: 0.0000e+00 - dense_9_acc_7: 0.0240 - dense_9_acc_8: 0.8060 - dense_9_acc_9: 0.0000e+00 - dense_9_acc_10: 0.022 - ETA: 12:39 - loss: 23.1461 - dense_9_loss_1: 2.3591 - dense_9_loss_2: 2.3817 - dense_9_loss_3: 2.4032 - dense_9_loss_4: 2.4457 - dense_9_loss_5: 2.0643 - dense_9_loss_6: 2.2338 - dense_9_loss_7: 2.4619 - dense_9_loss_8: 1.9828 - dense_9_loss_9: 2.3101 - dense_9_loss_10: 2.5036 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.0183 - dense_9_acc_5: 0.8383 - dense_9_acc_6: 0.0000e+00 - dense_9_acc_7: 0.0200 - dense_9_acc_8: 0.8383 - dense_9_acc_9: 0.0000e+00 - dense_9_acc_10: 0.018 - ETA: 10:52 - loss: 23.0015 - dense_9_loss_1: 2.3427 - dense_9_loss_2: 2.3808 - dense_9_loss_3: 2.4221 - dense_9_loss_4: 2.4768 - dense_9_loss_5: 1.9412 - dense_9_loss_6: 2.1685 - dense_9_loss_7: 2.5208 - dense_9_loss_8: 1.8293 - dense_9_loss_9: 2.2941 - dense_9_loss_10: 2.6251 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.0157 - dense_9_acc_5: 0.8614 - dense_9_acc_6: 0.0000e+00 - dense_9_acc_7: 0.0171 - dense_9_acc_8: 0.8614 - dense_9_acc_9: 0.0000e+00 - dense_9_acc_10: 0.015 - ETA: 9:31 - loss: 22.8647 - dense_9_loss_1: 2.3294 - dense_9_loss_2: 2.3713 - dense_9_loss_3: 2.4247 - dense_9_loss_4: 2.5125 - dense_9_loss_5: 1.8589 - dense_9_loss_6: 2.0988 - dense_9_loss_7: 2.5648 - dense_9_loss_8: 1.7353 - dense_9_loss_9: 2.2598 - dense_9_loss_10: 2.7094 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.0137 - dense_9_acc_5: 0.8787 - dense_9_acc_6: 0.0000e+00 - dense_9_acc_7: 0.0150 - dense_9_acc_8: 0.8787 - dense_9_acc_9: 0.0000e+00 - dense_9_acc_10: 0.013 - ETA: 8:28 - loss: 22.7467 - dense_9_loss_1: 2.3169 - dense_9_loss_2: 2.3619 - dense_9_loss_3: 2.4286 - dense_9_loss_4: 2.5247 - dense_9_loss_5: 1.8150 - dense_9_loss_6: 2.0352 - dense_9_loss_7: 2.5949 - dense_9_loss_8: 1.6933 - dense_9_loss_9: 2.2239 - dense_9_loss_10: 2.7525 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.0122 - dense_9_acc_5: 0.8922 - dense_9_acc_6: 0.0000e+00 - dense_9_acc_7: 0.0167 - dense_9_acc_8: 0.7911 - dense_9_acc_9: 0.0256 - dense_9_acc_10: 0.0278   - ETA: 7:37 - loss: 22.6234 - dense_9_loss_1: 2.3073 - dense_9_loss_2: 2.3493 - dense_9_loss_3: 2.4256 - dense_9_loss_4: 2.5370 - dense_9_loss_5: 1.7961 - dense_9_loss_6: 1.9916 - dense_9_loss_7: 2.5990 - dense_9_loss_8: 1.6826 - dense_9_loss_9: 2.1842 - dense_9_loss_10: 2.7506 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0000e+00 - dense_9_acc_4: 0.0150 - dense_9_acc_5: 0.8180 - dense_9_acc_6: 0.0640 - dense_9_acc_7: 0.0250 - dense_9_acc_8: 0.7120 - dense_9_acc_9: 0.0490 - dense_9_acc_10: 0.0380   - ETA: 6:56 - loss: 22.5271 - dense_9_loss_1: 2.2995 - dense_9_loss_2: 2.3365 - dense_9_loss_3: 2.4206 - dense_9_loss_4: 2.5424 - dense_9_loss_5: 1.7890 - dense_9_loss_6: 1.9613 - dense_9_loss_7: 2.5948 - dense_9_loss_8: 1.6847 - dense_9_loss_9: 2.1543 - dense_9_loss_10: 2.7441 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0036 - dense_9_acc_4: 0.0218 - dense_9_acc_5: 0.7455 - dense_9_acc_6: 0.1209 - dense_9_acc_7: 0.0355 - dense_9_acc_8: 0.6473 - dense_9_acc_9: 0.0800 - dense_9_acc_10: 0.0409   - ETA: 6:21 - loss: 22.4491 - dense_9_loss_1: 2.2936 - dense_9_loss_2: 2.3210 - dense_9_loss_3: 2.4066 - dense_9_loss_4: 2.5454 - dense_9_loss_5: 1.7839 - dense_9_loss_6: 1.9383 - dense_9_loss_7: 2.5963 - dense_9_loss_8: 1.6878 - dense_9_loss_9: 2.1337 - dense_9_loss_10: 2.7426 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0050 - dense_9_acc_4: 0.0283 - dense_9_acc_5: 0.6975 - dense_9_acc_6: 0.1733 - dense_9_acc_7: 0.0383 - dense_9_acc_8: 0.5933 - dense_9_acc_9: 0.0925 - dense_9_acc_10: 0.04 - ETA: 5:51 - loss: 22.3763 - dense_9_loss_1: 2.2870 - dense_9_loss_2: 2.3086 - dense_9_loss_3: 2.4018 - dense_9_loss_4: 2.5469 - dense_9_loss_5: 1.7774 - dense_9_loss_6: 1.9214 - dense_9_loss_7: 2.5996 - dense_9_loss_8: 1.6875 - dense_9_loss_9: 2.1150 - dense_9_loss_10: 2.7312 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0046 - dense_9_acc_4: 0.0262 - dense_9_acc_5: 0.7100 - dense_9_acc_6: 0.1869 - dense_9_acc_7: 0.0392 - dense_9_acc_8: 0.5531 - dense_9_acc_9: 0.1115 - dense_9_acc_10: 0.05 - ETA: 5:26 - loss: 22.3104 - dense_9_loss_1: 2.2807 - dense_9_loss_2: 2.2957 - dense_9_loss_3: 2.3947 - dense_9_loss_4: 2.5486 - dense_9_loss_5: 1.7669 - dense_9_loss_6: 1.9083 - dense_9_loss_7: 2.6007 - dense_9_loss_8: 1.6811 - dense_9_loss_9: 2.1006 - dense_9_loss_10: 2.7332 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0043 - dense_9_acc_4: 0.0243 - dense_9_acc_5: 0.7307 - dense_9_acc_6: 0.1736 - dense_9_acc_7: 0.0364 - dense_9_acc_8: 0.5829 - dense_9_acc_9: 0.1057 - dense_9_acc_10: 0.05 - ETA: 5:04 - loss: 22.2504 - dense_9_loss_1: 2.2753 - dense_9_loss_2: 2.2812 - dense_9_loss_3: 2.3900 - dense_9_loss_4: 2.5624 - dense_9_loss_5: 1.7509 - dense_9_loss_6: 1.8975 - dense_9_loss_7: 2.5969 - dense_9_loss_8: 1.6673 - dense_9_loss_9: 2.0865 - dense_9_loss_10: 2.7424 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0040 - dense_9_acc_4: 0.0227 - dense_9_acc_5: 0.7487 - dense_9_acc_6: 0.1620 - dense_9_acc_7: 0.0340 - dense_9_acc_8: 0.6107 - dense_9_acc_9: 0.0987 - dense_9_acc_10: 0.04 - ETA: 4:45 - loss: 22.1918 - dense_9_loss_1: 2.2702 - dense_9_loss_2: 2.2662 - dense_9_loss_3: 2.3868 - dense_9_loss_4: 2.5751 - dense_9_loss_5: 1.7308 - dense_9_loss_6: 1.8866 - dense_9_loss_7: 2.6032 - dense_9_loss_8: 1.6478 - dense_9_loss_9: 2.0785 - dense_9_loss_10: 2.7465 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0037 - dense_9_acc_4: 0.0213 - dense_9_acc_5: 0.7644 - dense_9_acc_6: 0.1519 - dense_9_acc_7: 0.0319 - dense_9_acc_8: 0.6350 - dense_9_acc_9: 0.0925 - dense_9_acc_10: 0.0456\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3200/10000 [========>.....................] - ETA: 4:28 - loss: 22.1521 - dense_9_loss_1: 2.2646 - dense_9_loss_2: 2.2507 - dense_9_loss_3: 2.3842 - dense_9_loss_4: 2.5890 - dense_9_loss_5: 1.7079 - dense_9_loss_6: 1.8759 - dense_9_loss_7: 2.6209 - dense_9_loss_8: 1.6245 - dense_9_loss_9: 2.0718 - dense_9_loss_10: 2.7626 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0035 - dense_9_acc_4: 0.0200 - dense_9_acc_5: 0.7782 - dense_9_acc_6: 0.1429 - dense_9_acc_7: 0.0300 - dense_9_acc_8: 0.6565 - dense_9_acc_9: 0.0871 - dense_9_acc_10: 0.04 - ETA: 4:12 - loss: 22.0846 - dense_9_loss_1: 2.2607 - dense_9_loss_2: 2.2335 - dense_9_loss_3: 2.3797 - dense_9_loss_4: 2.5974 - dense_9_loss_5: 1.6837 - dense_9_loss_6: 1.8670 - dense_9_loss_7: 2.6257 - dense_9_loss_8: 1.5995 - dense_9_loss_9: 2.0673 - dense_9_loss_10: 2.7700 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0033 - dense_9_acc_4: 0.0189 - dense_9_acc_5: 0.7906 - dense_9_acc_6: 0.1350 - dense_9_acc_7: 0.0283 - dense_9_acc_8: 0.6756 - dense_9_acc_9: 0.0822 - dense_9_acc_10: 0.04 - ETA: 3:58 - loss: 22.0342 - dense_9_loss_1: 2.2576 - dense_9_loss_2: 2.2155 - dense_9_loss_3: 2.3713 - dense_9_loss_4: 2.6124 - dense_9_loss_5: 1.6608 - dense_9_loss_6: 1.8564 - dense_9_loss_7: 2.6418 - dense_9_loss_8: 1.5757 - dense_9_loss_9: 2.0610 - dense_9_loss_10: 2.7818 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0032 - dense_9_acc_4: 0.0179 - dense_9_acc_5: 0.8016 - dense_9_acc_6: 0.1279 - dense_9_acc_7: 0.0268 - dense_9_acc_8: 0.6926 - dense_9_acc_9: 0.0779 - dense_9_acc_10: 0.03 - ETA: 3:46 - loss: 21.9861 - dense_9_loss_1: 2.2528 - dense_9_loss_2: 2.1969 - dense_9_loss_3: 2.3706 - dense_9_loss_4: 2.6266 - dense_9_loss_5: 1.6407 - dense_9_loss_6: 1.8449 - dense_9_loss_7: 2.6560 - dense_9_loss_8: 1.5550 - dense_9_loss_9: 2.0586 - dense_9_loss_10: 2.7840 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0000e+00 - dense_9_acc_3: 0.0030 - dense_9_acc_4: 0.0170 - dense_9_acc_5: 0.8115 - dense_9_acc_6: 0.1215 - dense_9_acc_7: 0.0255 - dense_9_acc_8: 0.7080 - dense_9_acc_9: 0.0740 - dense_9_acc_10: 0.03 - ETA: 3:35 - loss: 21.9359 - dense_9_loss_1: 2.2494 - dense_9_loss_2: 2.1780 - dense_9_loss_3: 2.3651 - dense_9_loss_4: 2.6331 - dense_9_loss_5: 1.6245 - dense_9_loss_6: 1.8335 - dense_9_loss_7: 2.6632 - dense_9_loss_8: 1.5391 - dense_9_loss_9: 2.0578 - dense_9_loss_10: 2.7922 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0052 - dense_9_acc_3: 0.0029 - dense_9_acc_4: 0.0162 - dense_9_acc_5: 0.8205 - dense_9_acc_6: 0.1157 - dense_9_acc_7: 0.0243 - dense_9_acc_8: 0.7219 - dense_9_acc_9: 0.0705 - dense_9_acc_10: 0.0348   - ETA: 3:25 - loss: 21.8772 - dense_9_loss_1: 2.2473 - dense_9_loss_2: 2.1591 - dense_9_loss_3: 2.3548 - dense_9_loss_4: 2.6436 - dense_9_loss_5: 1.6119 - dense_9_loss_6: 1.8201 - dense_9_loss_7: 2.6703 - dense_9_loss_8: 1.5277 - dense_9_loss_9: 2.0538 - dense_9_loss_10: 2.7885 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0305 - dense_9_acc_3: 0.0114 - dense_9_acc_4: 0.0164 - dense_9_acc_5: 0.8286 - dense_9_acc_6: 0.1105 - dense_9_acc_7: 0.0232 - dense_9_acc_8: 0.7345 - dense_9_acc_9: 0.0673 - dense_9_acc_10: 0.03 - ETA: 3:16 - loss: 21.8294 - dense_9_loss_1: 2.2452 - dense_9_loss_2: 2.1409 - dense_9_loss_3: 2.3459 - dense_9_loss_4: 2.6546 - dense_9_loss_5: 1.6020 - dense_9_loss_6: 1.8076 - dense_9_loss_7: 2.6748 - dense_9_loss_8: 1.5201 - dense_9_loss_9: 2.0488 - dense_9_loss_10: 2.7896 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0539 - dense_9_acc_3: 0.0174 - dense_9_acc_4: 0.0187 - dense_9_acc_5: 0.8278 - dense_9_acc_6: 0.1083 - dense_9_acc_7: 0.0222 - dense_9_acc_8: 0.7417 - dense_9_acc_9: 0.0665 - dense_9_acc_10: 0.03 - ETA: 3:07 - loss: 21.7885 - dense_9_loss_1: 2.2432 - dense_9_loss_2: 2.1233 - dense_9_loss_3: 2.3396 - dense_9_loss_4: 2.6642 - dense_9_loss_5: 1.5935 - dense_9_loss_6: 1.7957 - dense_9_loss_7: 2.6819 - dense_9_loss_8: 1.5150 - dense_9_loss_9: 2.0453 - dense_9_loss_10: 2.7869 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.0792 - dense_9_acc_3: 0.0279 - dense_9_acc_4: 0.0217 - dense_9_acc_5: 0.8238 - dense_9_acc_6: 0.1092 - dense_9_acc_7: 0.0217 - dense_9_acc_8: 0.7454 - dense_9_acc_9: 0.0662 - dense_9_acc_10: 0.03 - ETA: 2:59 - loss: 21.7517 - dense_9_loss_1: 2.2368 - dense_9_loss_2: 2.1059 - dense_9_loss_3: 2.3374 - dense_9_loss_4: 2.6787 - dense_9_loss_5: 1.5853 - dense_9_loss_6: 1.7851 - dense_9_loss_7: 2.6863 - dense_9_loss_8: 1.5114 - dense_9_loss_9: 2.0416 - dense_9_loss_10: 2.7832 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.1044 - dense_9_acc_3: 0.0328 - dense_9_acc_4: 0.0224 - dense_9_acc_5: 0.8264 - dense_9_acc_6: 0.1056 - dense_9_acc_7: 0.0208 - dense_9_acc_8: 0.7544 - dense_9_acc_9: 0.0644 - dense_9_acc_10: 0.03 - ETA: 2:51 - loss: 21.7015 - dense_9_loss_1: 2.2341 - dense_9_loss_2: 2.0885 - dense_9_loss_3: 2.3251 - dense_9_loss_4: 2.6848 - dense_9_loss_5: 1.5767 - dense_9_loss_6: 1.7771 - dense_9_loss_7: 2.6922 - dense_9_loss_8: 1.5084 - dense_9_loss_9: 2.0336 - dense_9_loss_10: 2.7809 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.1242 - dense_9_acc_3: 0.0427 - dense_9_acc_4: 0.0231 - dense_9_acc_5: 0.8331 - dense_9_acc_6: 0.1015 - dense_9_acc_7: 0.0200 - dense_9_acc_8: 0.7638 - dense_9_acc_9: 0.0619 - dense_9_acc_10: 0.03 - ETA: 2:44 - loss: 21.6597 - dense_9_loss_1: 2.2288 - dense_9_loss_2: 2.0698 - dense_9_loss_3: 2.3236 - dense_9_loss_4: 2.6926 - dense_9_loss_5: 1.5672 - dense_9_loss_6: 1.7713 - dense_9_loss_7: 2.6955 - dense_9_loss_8: 1.5048 - dense_9_loss_9: 2.0259 - dense_9_loss_10: 2.7802 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.1441 - dense_9_acc_3: 0.0467 - dense_9_acc_4: 0.0230 - dense_9_acc_5: 0.8393 - dense_9_acc_6: 0.0978 - dense_9_acc_7: 0.0193 - dense_9_acc_8: 0.7726 - dense_9_acc_9: 0.0596 - dense_9_acc_10: 0.03 - ETA: 2:38 - loss: 21.6142 - dense_9_loss_1: 2.2244 - dense_9_loss_2: 2.0491 - dense_9_loss_3: 2.3175 - dense_9_loss_4: 2.7033 - dense_9_loss_5: 1.5570 - dense_9_loss_6: 1.7663 - dense_9_loss_7: 2.6979 - dense_9_loss_8: 1.4997 - dense_9_loss_9: 2.0204 - dense_9_loss_10: 2.7786 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.1618 - dense_9_acc_3: 0.0550 - dense_9_acc_4: 0.0229 - dense_9_acc_5: 0.8450 - dense_9_acc_6: 0.0943 - dense_9_acc_7: 0.0186 - dense_9_acc_8: 0.7807 - dense_9_acc_9: 0.0575 - dense_9_acc_10: 0.03 - ETA: 2:31 - loss: 21.5564 - dense_9_loss_1: 2.2236 - dense_9_loss_2: 2.0285 - dense_9_loss_3: 2.3042 - dense_9_loss_4: 2.7134 - dense_9_loss_5: 1.5457 - dense_9_loss_6: 1.7626 - dense_9_loss_7: 2.6938 - dense_9_loss_8: 1.4930 - dense_9_loss_9: 2.0156 - dense_9_loss_10: 2.7759 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.1755 - dense_9_acc_3: 0.0648 - dense_9_acc_4: 0.0228 - dense_9_acc_5: 0.8503 - dense_9_acc_6: 0.0910 - dense_9_acc_7: 0.0179 - dense_9_acc_8: 0.7883 - dense_9_acc_9: 0.0555 - dense_9_acc_10: 0.02 - ETA: 2:26 - loss: 21.5108 - dense_9_loss_1: 2.2203 - dense_9_loss_2: 2.0045 - dense_9_loss_3: 2.2983 - dense_9_loss_4: 2.7280 - dense_9_loss_5: 1.5345 - dense_9_loss_6: 1.7576 - dense_9_loss_7: 2.6977 - dense_9_loss_8: 1.4857 - dense_9_loss_9: 2.0120 - dense_9_loss_10: 2.7722 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.1910 - dense_9_acc_3: 0.0717 - dense_9_acc_4: 0.0247 - dense_9_acc_5: 0.8533 - dense_9_acc_6: 0.0880 - dense_9_acc_7: 0.0173 - dense_9_acc_8: 0.7953 - dense_9_acc_9: 0.0537 - dense_9_acc_10: 0.02 - ETA: 2:20 - loss: 21.4608 - dense_9_loss_1: 2.2195 - dense_9_loss_2: 1.9821 - dense_9_loss_3: 2.2896 - dense_9_loss_4: 2.7361 - dense_9_loss_5: 1.5229 - dense_9_loss_6: 1.7520 - dense_9_loss_7: 2.6996 - dense_9_loss_8: 1.4805 - dense_9_loss_9: 2.0077 - dense_9_loss_10: 2.7709 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.2042 - dense_9_acc_3: 0.0787 - dense_9_acc_4: 0.0268 - dense_9_acc_5: 0.8516 - dense_9_acc_6: 0.0865 - dense_9_acc_7: 0.0168 - dense_9_acc_8: 0.8016 - dense_9_acc_9: 0.0526 - dense_9_acc_10: 0.02 - ETA: 2:15 - loss: 21.4100 - dense_9_loss_1: 2.2156 - dense_9_loss_2: 1.9583 - dense_9_loss_3: 2.2838 - dense_9_loss_4: 2.7408 - dense_9_loss_5: 1.5109 - dense_9_loss_6: 1.7473 - dense_9_loss_7: 2.6980 - dense_9_loss_8: 1.4777 - dense_9_loss_9: 2.0046 - dense_9_loss_10: 2.7730 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.2184 - dense_9_acc_3: 0.0863 - dense_9_acc_4: 0.0284 - dense_9_acc_5: 0.8497 - dense_9_acc_6: 0.0872 - dense_9_acc_7: 0.0162 - dense_9_acc_8: 0.8041 - dense_9_acc_9: 0.0525 - dense_9_acc_10: 0.0287"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4800/10000 [=============>................] - ETA: 2:10 - loss: 21.3623 - dense_9_loss_1: 2.2117 - dense_9_loss_2: 1.9350 - dense_9_loss_3: 2.2799 - dense_9_loss_4: 2.7521 - dense_9_loss_5: 1.4983 - dense_9_loss_6: 1.7404 - dense_9_loss_7: 2.6990 - dense_9_loss_8: 1.4747 - dense_9_loss_9: 1.9992 - dense_9_loss_10: 2.7721 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.2312 - dense_9_acc_3: 0.0927 - dense_9_acc_4: 0.0303 - dense_9_acc_5: 0.8488 - dense_9_acc_6: 0.0864 - dense_9_acc_7: 0.0158 - dense_9_acc_8: 0.8076 - dense_9_acc_9: 0.0552 - dense_9_acc_10: 0.03 - ETA: 2:06 - loss: 21.3164 - dense_9_loss_1: 2.2110 - dense_9_loss_2: 1.9145 - dense_9_loss_3: 2.2703 - dense_9_loss_4: 2.7616 - dense_9_loss_5: 1.4864 - dense_9_loss_6: 1.7333 - dense_9_loss_7: 2.7032 - dense_9_loss_8: 1.4729 - dense_9_loss_9: 1.9948 - dense_9_loss_10: 2.7685 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.2403 - dense_9_acc_3: 0.1012 - dense_9_acc_4: 0.0324 - dense_9_acc_5: 0.8462 - dense_9_acc_6: 0.0879 - dense_9_acc_7: 0.0153 - dense_9_acc_8: 0.8068 - dense_9_acc_9: 0.0603 - dense_9_acc_10: 0.03 - ETA: 2:01 - loss: 21.2650 - dense_9_loss_1: 2.2035 - dense_9_loss_2: 1.8909 - dense_9_loss_3: 2.2641 - dense_9_loss_4: 2.7705 - dense_9_loss_5: 1.4761 - dense_9_loss_6: 1.7250 - dense_9_loss_7: 2.7042 - dense_9_loss_8: 1.4707 - dense_9_loss_9: 1.9911 - dense_9_loss_10: 2.7690 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.2543 - dense_9_acc_3: 0.1071 - dense_9_acc_4: 0.0334 - dense_9_acc_5: 0.8394 - dense_9_acc_6: 0.0931 - dense_9_acc_7: 0.0149 - dense_9_acc_8: 0.8017 - dense_9_acc_9: 0.0657 - dense_9_acc_10: 0.03 - ETA: 1:57 - loss: 21.2114 - dense_9_loss_1: 2.1989 - dense_9_loss_2: 1.8693 - dense_9_loss_3: 2.2546 - dense_9_loss_4: 2.7766 - dense_9_loss_5: 1.4670 - dense_9_loss_6: 1.7166 - dense_9_loss_7: 2.7067 - dense_9_loss_8: 1.4679 - dense_9_loss_9: 1.9860 - dense_9_loss_10: 2.7676 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.2647 - dense_9_acc_3: 0.1153 - dense_9_acc_4: 0.0358 - dense_9_acc_5: 0.8322 - dense_9_acc_6: 0.1000 - dense_9_acc_7: 0.0144 - dense_9_acc_8: 0.7942 - dense_9_acc_9: 0.0717 - dense_9_acc_10: 0.03 - ETA: 1:53 - loss: 21.1586 - dense_9_loss_1: 2.1929 - dense_9_loss_2: 1.8492 - dense_9_loss_3: 2.2481 - dense_9_loss_4: 2.7858 - dense_9_loss_5: 1.4574 - dense_9_loss_6: 1.7116 - dense_9_loss_7: 2.7048 - dense_9_loss_8: 1.4648 - dense_9_loss_9: 1.9801 - dense_9_loss_10: 2.7640 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.2749 - dense_9_acc_3: 0.1205 - dense_9_acc_4: 0.0362 - dense_9_acc_5: 0.8305 - dense_9_acc_6: 0.1005 - dense_9_acc_7: 0.0149 - dense_9_acc_8: 0.7897 - dense_9_acc_9: 0.0768 - dense_9_acc_10: 0.04 - ETA: 1:49 - loss: 21.1112 - dense_9_loss_1: 2.1876 - dense_9_loss_2: 1.8319 - dense_9_loss_3: 2.2406 - dense_9_loss_4: 2.7942 - dense_9_loss_5: 1.4471 - dense_9_loss_6: 1.7078 - dense_9_loss_7: 2.7048 - dense_9_loss_8: 1.4635 - dense_9_loss_9: 1.9740 - dense_9_loss_10: 2.7596 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.2837 - dense_9_acc_3: 0.1261 - dense_9_acc_4: 0.0363 - dense_9_acc_5: 0.8337 - dense_9_acc_6: 0.0984 - dense_9_acc_7: 0.0161 - dense_9_acc_8: 0.7863 - dense_9_acc_9: 0.0839 - dense_9_acc_10: 0.04 - ETA: 1:46 - loss: 21.0567 - dense_9_loss_1: 2.1778 - dense_9_loss_2: 1.8122 - dense_9_loss_3: 2.2310 - dense_9_loss_4: 2.7978 - dense_9_loss_5: 1.4373 - dense_9_loss_6: 1.7036 - dense_9_loss_7: 2.7080 - dense_9_loss_8: 1.4607 - dense_9_loss_9: 1.9682 - dense_9_loss_10: 2.7602 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.2962 - dense_9_acc_3: 0.1328 - dense_9_acc_4: 0.0377 - dense_9_acc_5: 0.8349 - dense_9_acc_6: 0.0959 - dense_9_acc_7: 0.0167 - dense_9_acc_8: 0.7872 - dense_9_acc_9: 0.0903 - dense_9_acc_10: 0.04 - ETA: 1:42 - loss: 21.0061 - dense_9_loss_1: 2.1707 - dense_9_loss_2: 1.7938 - dense_9_loss_3: 2.2195 - dense_9_loss_4: 2.7994 - dense_9_loss_5: 1.4295 - dense_9_loss_6: 1.6996 - dense_9_loss_7: 2.7121 - dense_9_loss_8: 1.4533 - dense_9_loss_9: 1.9705 - dense_9_loss_10: 2.7577 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.3055 - dense_9_acc_3: 0.1403 - dense_9_acc_4: 0.0395 - dense_9_acc_5: 0.8338 - dense_9_acc_6: 0.0957 - dense_9_acc_7: 0.0162 - dense_9_acc_8: 0.7912 - dense_9_acc_9: 0.0890 - dense_9_acc_10: 0.04 - ETA: 1:39 - loss: 20.9516 - dense_9_loss_1: 2.1628 - dense_9_loss_2: 1.7763 - dense_9_loss_3: 2.2059 - dense_9_loss_4: 2.8051 - dense_9_loss_5: 1.4203 - dense_9_loss_6: 1.6969 - dense_9_loss_7: 2.7129 - dense_9_loss_8: 1.4488 - dense_9_loss_9: 1.9687 - dense_9_loss_10: 2.7537 - dense_9_acc_1: 0.0000e+00 - dense_9_acc_2: 0.3161 - dense_9_acc_3: 0.1493 - dense_9_acc_4: 0.0410 - dense_9_acc_5: 0.8344 - dense_9_acc_6: 0.0934 - dense_9_acc_7: 0.0161 - dense_9_acc_8: 0.7939 - dense_9_acc_9: 0.0912 - dense_9_acc_10: 0.05 - ETA: 1:36 - loss: 20.9070 - dense_9_loss_1: 2.1526 - dense_9_loss_2: 1.7605 - dense_9_loss_3: 2.1957 - dense_9_loss_4: 2.8113 - dense_9_loss_5: 1.4094 - dense_9_loss_6: 1.6961 - dense_9_loss_7: 2.7131 - dense_9_loss_8: 1.4519 - dense_9_loss_9: 1.9598 - dense_9_loss_10: 2.7567 - dense_9_acc_1: 0.0021 - dense_9_acc_2: 0.3271 - dense_9_acc_3: 0.1560 - dense_9_acc_4: 0.0414 - dense_9_acc_5: 0.8383 - dense_9_acc_6: 0.0912 - dense_9_acc_7: 0.0176 - dense_9_acc_8: 0.7836 - dense_9_acc_9: 0.1012 - dense_9_acc_10: 0.0514   - ETA: 1:33 - loss: 20.8496 - dense_9_loss_1: 2.1407 - dense_9_loss_2: 1.7450 - dense_9_loss_3: 2.1857 - dense_9_loss_4: 2.8125 - dense_9_loss_5: 1.3983 - dense_9_loss_6: 1.6948 - dense_9_loss_7: 2.7097 - dense_9_loss_8: 1.4526 - dense_9_loss_9: 1.9549 - dense_9_loss_10: 2.7555 - dense_9_acc_1: 0.0072 - dense_9_acc_2: 0.3370 - dense_9_acc_3: 0.1609 - dense_9_acc_4: 0.0421 - dense_9_acc_5: 0.8421 - dense_9_acc_6: 0.0895 - dense_9_acc_7: 0.0198 - dense_9_acc_8: 0.7758 - dense_9_acc_9: 0.1084 - dense_9_acc_10: 0.05 - ETA: 1:30 - loss: 20.7942 - dense_9_loss_1: 2.1315 - dense_9_loss_2: 1.7303 - dense_9_loss_3: 2.1730 - dense_9_loss_4: 2.8143 - dense_9_loss_5: 1.3887 - dense_9_loss_6: 1.6927 - dense_9_loss_7: 2.7134 - dense_9_loss_8: 1.4445 - dense_9_loss_9: 1.9514 - dense_9_loss_10: 2.7545 - dense_9_acc_1: 0.0086 - dense_9_acc_2: 0.3430 - dense_9_acc_3: 0.1666 - dense_9_acc_4: 0.0443 - dense_9_acc_5: 0.8457 - dense_9_acc_6: 0.0875 - dense_9_acc_7: 0.0193 - dense_9_acc_8: 0.7795 - dense_9_acc_9: 0.1120 - dense_9_acc_10: 0.05 - ETA: 1:27 - loss: 20.7368 - dense_9_loss_1: 2.1177 - dense_9_loss_2: 1.7123 - dense_9_loss_3: 2.1628 - dense_9_loss_4: 2.8185 - dense_9_loss_5: 1.3796 - dense_9_loss_6: 1.6887 - dense_9_loss_7: 2.7189 - dense_9_loss_8: 1.4373 - dense_9_loss_9: 1.9489 - dense_9_loss_10: 2.7521 - dense_9_acc_1: 0.0180 - dense_9_acc_2: 0.3551 - dense_9_acc_3: 0.1711 - dense_9_acc_4: 0.0451 - dense_9_acc_5: 0.8431 - dense_9_acc_6: 0.0878 - dense_9_acc_7: 0.0189 - dense_9_acc_8: 0.7802 - dense_9_acc_9: 0.1131 - dense_9_acc_10: 0.05 - ETA: 1:24 - loss: 20.6818 - dense_9_loss_1: 2.1053 - dense_9_loss_2: 1.6963 - dense_9_loss_3: 2.1529 - dense_9_loss_4: 2.8227 - dense_9_loss_5: 1.3724 - dense_9_loss_6: 1.6816 - dense_9_loss_7: 2.7229 - dense_9_loss_8: 1.4349 - dense_9_loss_9: 1.9441 - dense_9_loss_10: 2.7486 - dense_9_acc_1: 0.0296 - dense_9_acc_2: 0.3667 - dense_9_acc_3: 0.1757 - dense_9_acc_4: 0.0461 - dense_9_acc_5: 0.8365 - dense_9_acc_6: 0.0937 - dense_9_acc_7: 0.0187 - dense_9_acc_8: 0.7743 - dense_9_acc_9: 0.1187 - dense_9_acc_10: 0.06 - ETA: 1:21 - loss: 20.6228 - dense_9_loss_1: 2.0931 - dense_9_loss_2: 1.6801 - dense_9_loss_3: 2.1403 - dense_9_loss_4: 2.8262 - dense_9_loss_5: 1.3653 - dense_9_loss_6: 1.6772 - dense_9_loss_7: 2.7214 - dense_9_loss_8: 1.4367 - dense_9_loss_9: 1.9390 - dense_9_loss_10: 2.7436 - dense_9_acc_1: 0.0406 - dense_9_acc_2: 0.3768 - dense_9_acc_3: 0.1821 - dense_9_acc_4: 0.0472 - dense_9_acc_5: 0.8343 - dense_9_acc_6: 0.0951 - dense_9_acc_7: 0.0196 - dense_9_acc_8: 0.7662 - dense_9_acc_9: 0.1245 - dense_9_acc_10: 0.06 - ETA: 1:19 - loss: 20.5658 - dense_9_loss_1: 2.0819 - dense_9_loss_2: 1.6662 - dense_9_loss_3: 2.1315 - dense_9_loss_4: 2.8240 - dense_9_loss_5: 1.3565 - dense_9_loss_6: 1.6738 - dense_9_loss_7: 2.7194 - dense_9_loss_8: 1.4399 - dense_9_loss_9: 1.9334 - dense_9_loss_10: 2.7391 - dense_9_acc_1: 0.0513 - dense_9_acc_2: 0.3854 - dense_9_acc_3: 0.1858 - dense_9_acc_4: 0.0500 - dense_9_acc_5: 0.8354 - dense_9_acc_6: 0.0933 - dense_9_acc_7: 0.0206 - dense_9_acc_8: 0.7560 - dense_9_acc_9: 0.1310 - dense_9_acc_10: 0.0637"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6400/10000 [==================>...........] - ETA: 1:16 - loss: 20.5207 - dense_9_loss_1: 2.0717 - dense_9_loss_2: 1.6537 - dense_9_loss_3: 2.1211 - dense_9_loss_4: 2.8275 - dense_9_loss_5: 1.3451 - dense_9_loss_6: 1.6725 - dense_9_loss_7: 2.7261 - dense_9_loss_8: 1.4393 - dense_9_loss_9: 1.9294 - dense_9_loss_10: 2.7345 - dense_9_acc_1: 0.0616 - dense_9_acc_2: 0.3927 - dense_9_acc_3: 0.1908 - dense_9_acc_4: 0.0502 - dense_9_acc_5: 0.8386 - dense_9_acc_6: 0.0914 - dense_9_acc_7: 0.0204 - dense_9_acc_8: 0.7555 - dense_9_acc_9: 0.1361 - dense_9_acc_10: 0.06 - ETA: 1:14 - loss: 20.4709 - dense_9_loss_1: 2.0586 - dense_9_loss_2: 1.6394 - dense_9_loss_3: 2.1144 - dense_9_loss_4: 2.8317 - dense_9_loss_5: 1.3338 - dense_9_loss_6: 1.6708 - dense_9_loss_7: 2.7310 - dense_9_loss_8: 1.4347 - dense_9_loss_9: 1.9260 - dense_9_loss_10: 2.7305 - dense_9_acc_1: 0.0728 - dense_9_acc_2: 0.4022 - dense_9_acc_3: 0.1932 - dense_9_acc_4: 0.0504 - dense_9_acc_5: 0.8416 - dense_9_acc_6: 0.0896 - dense_9_acc_7: 0.0202 - dense_9_acc_8: 0.7576 - dense_9_acc_9: 0.1400 - dense_9_acc_10: 0.06 - ETA: 1:12 - loss: 20.4103 - dense_9_loss_1: 2.0433 - dense_9_loss_2: 1.6238 - dense_9_loss_3: 2.1039 - dense_9_loss_4: 2.8325 - dense_9_loss_5: 1.3244 - dense_9_loss_6: 1.6679 - dense_9_loss_7: 2.7324 - dense_9_loss_8: 1.4292 - dense_9_loss_9: 1.9231 - dense_9_loss_10: 2.7298 - dense_9_acc_1: 0.0847 - dense_9_acc_2: 0.4127 - dense_9_acc_3: 0.1978 - dense_9_acc_4: 0.0506 - dense_9_acc_5: 0.8435 - dense_9_acc_6: 0.0878 - dense_9_acc_7: 0.0200 - dense_9_acc_8: 0.7598 - dense_9_acc_9: 0.1410 - dense_9_acc_10: 0.06 - ETA: 1:09 - loss: 20.3610 - dense_9_loss_1: 2.0305 - dense_9_loss_2: 1.6090 - dense_9_loss_3: 2.0936 - dense_9_loss_4: 2.8353 - dense_9_loss_5: 1.3189 - dense_9_loss_6: 1.6643 - dense_9_loss_7: 2.7341 - dense_9_loss_8: 1.4270 - dense_9_loss_9: 1.9219 - dense_9_loss_10: 2.7264 - dense_9_acc_1: 0.0950 - dense_9_acc_2: 0.4212 - dense_9_acc_3: 0.2019 - dense_9_acc_4: 0.0517 - dense_9_acc_5: 0.8415 - dense_9_acc_6: 0.0883 - dense_9_acc_7: 0.0196 - dense_9_acc_8: 0.7604 - dense_9_acc_9: 0.1446 - dense_9_acc_10: 0.06 - ETA: 1:07 - loss: 20.3089 - dense_9_loss_1: 2.0181 - dense_9_loss_2: 1.5957 - dense_9_loss_3: 2.0846 - dense_9_loss_4: 2.8348 - dense_9_loss_5: 1.3146 - dense_9_loss_6: 1.6598 - dense_9_loss_7: 2.7346 - dense_9_loss_8: 1.4272 - dense_9_loss_9: 1.9192 - dense_9_loss_10: 2.7203 - dense_9_acc_1: 0.1047 - dense_9_acc_2: 0.4289 - dense_9_acc_3: 0.2055 - dense_9_acc_4: 0.0528 - dense_9_acc_5: 0.8396 - dense_9_acc_6: 0.0891 - dense_9_acc_7: 0.0200 - dense_9_acc_8: 0.7572 - dense_9_acc_9: 0.1511 - dense_9_acc_10: 0.06 - ETA: 1:05 - loss: 20.2572 - dense_9_loss_1: 2.0055 - dense_9_loss_2: 1.5827 - dense_9_loss_3: 2.0760 - dense_9_loss_4: 2.8353 - dense_9_loss_5: 1.3075 - dense_9_loss_6: 1.6555 - dense_9_loss_7: 2.7367 - dense_9_loss_8: 1.4241 - dense_9_loss_9: 1.9168 - dense_9_loss_10: 2.7170 - dense_9_acc_1: 0.1135 - dense_9_acc_2: 0.4376 - dense_9_acc_3: 0.2096 - dense_9_acc_4: 0.0530 - dense_9_acc_5: 0.8387 - dense_9_acc_6: 0.0878 - dense_9_acc_7: 0.0200 - dense_9_acc_8: 0.7604 - dense_9_acc_9: 0.1567 - dense_9_acc_10: 0.06 - ETA: 1:03 - loss: 20.2045 - dense_9_loss_1: 1.9923 - dense_9_loss_2: 1.5699 - dense_9_loss_3: 2.0671 - dense_9_loss_4: 2.8359 - dense_9_loss_5: 1.2982 - dense_9_loss_6: 1.6532 - dense_9_loss_7: 2.7427 - dense_9_loss_8: 1.4185 - dense_9_loss_9: 1.9150 - dense_9_loss_10: 2.7118 - dense_9_acc_1: 0.1224 - dense_9_acc_2: 0.4453 - dense_9_acc_3: 0.2127 - dense_9_acc_4: 0.0524 - dense_9_acc_5: 0.8402 - dense_9_acc_6: 0.0862 - dense_9_acc_7: 0.0198 - dense_9_acc_8: 0.7636 - dense_9_acc_9: 0.1585 - dense_9_acc_10: 0.07 - ETA: 1:01 - loss: 20.1521 - dense_9_loss_1: 1.9785 - dense_9_loss_2: 1.5568 - dense_9_loss_3: 2.0577 - dense_9_loss_4: 2.8385 - dense_9_loss_5: 1.2890 - dense_9_loss_6: 1.6506 - dense_9_loss_7: 2.7468 - dense_9_loss_8: 1.4127 - dense_9_loss_9: 1.9121 - dense_9_loss_10: 2.7094 - dense_9_acc_1: 0.1311 - dense_9_acc_2: 0.4525 - dense_9_acc_3: 0.2164 - dense_9_acc_4: 0.0520 - dense_9_acc_5: 0.8407 - dense_9_acc_6: 0.0846 - dense_9_acc_7: 0.0196 - dense_9_acc_8: 0.7666 - dense_9_acc_9: 0.1614 - dense_9_acc_10: 0.07 - ETA: 59s - loss: 20.0929 - dense_9_loss_1: 1.9640 - dense_9_loss_2: 1.5438 - dense_9_loss_3: 2.0480 - dense_9_loss_4: 2.8384 - dense_9_loss_5: 1.2821 - dense_9_loss_6: 1.6459 - dense_9_loss_7: 2.7466 - dense_9_loss_8: 1.4108 - dense_9_loss_9: 1.9089 - dense_9_loss_10: 2.7045 - dense_9_acc_1: 0.1400 - dense_9_acc_2: 0.4591 - dense_9_acc_3: 0.2193 - dense_9_acc_4: 0.0518 - dense_9_acc_5: 0.8405 - dense_9_acc_6: 0.0847 - dense_9_acc_7: 0.0207 - dense_9_acc_8: 0.7656 - dense_9_acc_9: 0.1658 - dense_9_acc_10: 0.0737 - ETA: 57s - loss: 20.0331 - dense_9_loss_1: 1.9471 - dense_9_loss_2: 1.5314 - dense_9_loss_3: 2.0403 - dense_9_loss_4: 2.8373 - dense_9_loss_5: 1.2781 - dense_9_loss_6: 1.6386 - dense_9_loss_7: 2.7452 - dense_9_loss_8: 1.4102 - dense_9_loss_9: 1.9047 - dense_9_loss_10: 2.7002 - dense_9_acc_1: 0.1503 - dense_9_acc_2: 0.4666 - dense_9_acc_3: 0.2202 - dense_9_acc_4: 0.0531 - dense_9_acc_5: 0.8374 - dense_9_acc_6: 0.0893 - dense_9_acc_7: 0.0222 - dense_9_acc_8: 0.7614 - dense_9_acc_9: 0.1716 - dense_9_acc_10: 0.075 - ETA: 55s - loss: 19.9761 - dense_9_loss_1: 1.9308 - dense_9_loss_2: 1.5167 - dense_9_loss_3: 2.0317 - dense_9_loss_4: 2.8396 - dense_9_loss_5: 1.2731 - dense_9_loss_6: 1.6328 - dense_9_loss_7: 2.7442 - dense_9_loss_8: 1.4078 - dense_9_loss_9: 1.9016 - dense_9_loss_10: 2.6978 - dense_9_acc_1: 0.1597 - dense_9_acc_2: 0.4742 - dense_9_acc_3: 0.2227 - dense_9_acc_4: 0.0539 - dense_9_acc_5: 0.8353 - dense_9_acc_6: 0.0920 - dense_9_acc_7: 0.0234 - dense_9_acc_8: 0.7597 - dense_9_acc_9: 0.1739 - dense_9_acc_10: 0.075 - ETA: 53s - loss: 19.9153 - dense_9_loss_1: 1.9153 - dense_9_loss_2: 1.5019 - dense_9_loss_3: 2.0204 - dense_9_loss_4: 2.8410 - dense_9_loss_5: 1.2661 - dense_9_loss_6: 1.6276 - dense_9_loss_7: 2.7475 - dense_9_loss_8: 1.4028 - dense_9_loss_9: 1.8988 - dense_9_loss_10: 2.6940 - dense_9_acc_1: 0.1682 - dense_9_acc_2: 0.4813 - dense_9_acc_3: 0.2268 - dense_9_acc_4: 0.0550 - dense_9_acc_5: 0.8340 - dense_9_acc_6: 0.0925 - dense_9_acc_7: 0.0233 - dense_9_acc_8: 0.7623 - dense_9_acc_9: 0.1757 - dense_9_acc_10: 0.076 - ETA: 51s - loss: 19.8527 - dense_9_loss_1: 1.8997 - dense_9_loss_2: 1.4879 - dense_9_loss_3: 2.0102 - dense_9_loss_4: 2.8405 - dense_9_loss_5: 1.2587 - dense_9_loss_6: 1.6232 - dense_9_loss_7: 2.7503 - dense_9_loss_8: 1.3981 - dense_9_loss_9: 1.8954 - dense_9_loss_10: 2.6885 - dense_9_acc_1: 0.1759 - dense_9_acc_2: 0.4884 - dense_9_acc_3: 0.2307 - dense_9_acc_4: 0.0552 - dense_9_acc_5: 0.8334 - dense_9_acc_6: 0.0921 - dense_9_acc_7: 0.0234 - dense_9_acc_8: 0.7649 - dense_9_acc_9: 0.1793 - dense_9_acc_10: 0.077 - ETA: 49s - loss: 19.7904 - dense_9_loss_1: 1.8838 - dense_9_loss_2: 1.4747 - dense_9_loss_3: 1.9996 - dense_9_loss_4: 2.8411 - dense_9_loss_5: 1.2516 - dense_9_loss_6: 1.6185 - dense_9_loss_7: 2.7497 - dense_9_loss_8: 1.3937 - dense_9_loss_9: 1.8916 - dense_9_loss_10: 2.6861 - dense_9_acc_1: 0.1840 - dense_9_acc_2: 0.4948 - dense_9_acc_3: 0.2344 - dense_9_acc_4: 0.0556 - dense_9_acc_5: 0.8340 - dense_9_acc_6: 0.0918 - dense_9_acc_7: 0.0242 - dense_9_acc_8: 0.7661 - dense_9_acc_9: 0.1832 - dense_9_acc_10: 0.077 - ETA: 48s - loss: 19.7266 - dense_9_loss_1: 1.8676 - dense_9_loss_2: 1.4605 - dense_9_loss_3: 1.9893 - dense_9_loss_4: 2.8391 - dense_9_loss_5: 1.2457 - dense_9_loss_6: 1.6123 - dense_9_loss_7: 2.7516 - dense_9_loss_8: 1.3904 - dense_9_loss_9: 1.8902 - dense_9_loss_10: 2.6801 - dense_9_acc_1: 0.1917 - dense_9_acc_2: 0.5017 - dense_9_acc_3: 0.2376 - dense_9_acc_4: 0.0557 - dense_9_acc_5: 0.8324 - dense_9_acc_6: 0.0929 - dense_9_acc_7: 0.0248 - dense_9_acc_8: 0.7667 - dense_9_acc_9: 0.1863 - dense_9_acc_10: 0.080 - ETA: 46s - loss: 19.6713 - dense_9_loss_1: 1.8542 - dense_9_loss_2: 1.4490 - dense_9_loss_3: 1.9795 - dense_9_loss_4: 2.8378 - dense_9_loss_5: 1.2406 - dense_9_loss_6: 1.6070 - dense_9_loss_7: 2.7535 - dense_9_loss_8: 1.3850 - dense_9_loss_9: 1.8883 - dense_9_loss_10: 2.6764 - dense_9_acc_1: 0.1970 - dense_9_acc_2: 0.5075 - dense_9_acc_3: 0.2413 - dense_9_acc_4: 0.0569 - dense_9_acc_5: 0.8294 - dense_9_acc_6: 0.0948 - dense_9_acc_7: 0.0252 - dense_9_acc_8: 0.7681 - dense_9_acc_9: 0.1870 - dense_9_acc_10: 0.0811"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8000/10000 [=======================>......] - ETA: 44s - loss: 19.6163 - dense_9_loss_1: 1.8392 - dense_9_loss_2: 1.4366 - dense_9_loss_3: 1.9719 - dense_9_loss_4: 2.8380 - dense_9_loss_5: 1.2362 - dense_9_loss_6: 1.6002 - dense_9_loss_7: 2.7568 - dense_9_loss_8: 1.3807 - dense_9_loss_9: 1.8859 - dense_9_loss_10: 2.6707 - dense_9_acc_1: 0.2035 - dense_9_acc_2: 0.5135 - dense_9_acc_3: 0.2431 - dense_9_acc_4: 0.0578 - dense_9_acc_5: 0.8265 - dense_9_acc_6: 0.0982 - dense_9_acc_7: 0.0255 - dense_9_acc_8: 0.7691 - dense_9_acc_9: 0.1888 - dense_9_acc_10: 0.083 - ETA: 43s - loss: 19.5673 - dense_9_loss_1: 1.8243 - dense_9_loss_2: 1.4259 - dense_9_loss_3: 1.9656 - dense_9_loss_4: 2.8366 - dense_9_loss_5: 1.2327 - dense_9_loss_6: 1.5947 - dense_9_loss_7: 2.7608 - dense_9_loss_8: 1.3784 - dense_9_loss_9: 1.8829 - dense_9_loss_10: 2.6654 - dense_9_acc_1: 0.2105 - dense_9_acc_2: 0.5194 - dense_9_acc_3: 0.2445 - dense_9_acc_4: 0.0592 - dense_9_acc_5: 0.8218 - dense_9_acc_6: 0.1009 - dense_9_acc_7: 0.0255 - dense_9_acc_8: 0.7711 - dense_9_acc_9: 0.1929 - dense_9_acc_10: 0.084 - ETA: 41s - loss: 19.5015 - dense_9_loss_1: 1.8073 - dense_9_loss_2: 1.4116 - dense_9_loss_3: 1.9575 - dense_9_loss_4: 2.8354 - dense_9_loss_5: 1.2246 - dense_9_loss_6: 1.5922 - dense_9_loss_7: 2.7597 - dense_9_loss_8: 1.3729 - dense_9_loss_9: 1.8788 - dense_9_loss_10: 2.6613 - dense_9_acc_1: 0.2185 - dense_9_acc_2: 0.5260 - dense_9_acc_3: 0.2464 - dense_9_acc_4: 0.0597 - dense_9_acc_5: 0.8228 - dense_9_acc_6: 0.0996 - dense_9_acc_7: 0.0251 - dense_9_acc_8: 0.7731 - dense_9_acc_9: 0.1963 - dense_9_acc_10: 0.085 - ETA: 39s - loss: 19.4492 - dense_9_loss_1: 1.7925 - dense_9_loss_2: 1.4013 - dense_9_loss_3: 1.9518 - dense_9_loss_4: 2.8347 - dense_9_loss_5: 1.2158 - dense_9_loss_6: 1.5891 - dense_9_loss_7: 2.7639 - dense_9_loss_8: 1.3656 - dense_9_loss_9: 1.8772 - dense_9_loss_10: 2.6572 - dense_9_acc_1: 0.2250 - dense_9_acc_2: 0.5313 - dense_9_acc_3: 0.2475 - dense_9_acc_4: 0.0597 - dense_9_acc_5: 0.8253 - dense_9_acc_6: 0.0981 - dense_9_acc_7: 0.0251 - dense_9_acc_8: 0.7756 - dense_9_acc_9: 0.1981 - dense_9_acc_10: 0.087 - ETA: 38s - loss: 19.3950 - dense_9_loss_1: 1.7772 - dense_9_loss_2: 1.3911 - dense_9_loss_3: 1.9457 - dense_9_loss_4: 2.8340 - dense_9_loss_5: 1.2084 - dense_9_loss_6: 1.5842 - dense_9_loss_7: 2.7629 - dense_9_loss_8: 1.3626 - dense_9_loss_9: 1.8776 - dense_9_loss_10: 2.6512 - dense_9_acc_1: 0.2320 - dense_9_acc_2: 0.5357 - dense_9_acc_3: 0.2481 - dense_9_acc_4: 0.0599 - dense_9_acc_5: 0.8274 - dense_9_acc_6: 0.0988 - dense_9_acc_7: 0.0264 - dense_9_acc_8: 0.7758 - dense_9_acc_9: 0.1997 - dense_9_acc_10: 0.088 - ETA: 36s - loss: 19.3386 - dense_9_loss_1: 1.7618 - dense_9_loss_2: 1.3798 - dense_9_loss_3: 1.9384 - dense_9_loss_4: 2.8335 - dense_9_loss_5: 1.2023 - dense_9_loss_6: 1.5785 - dense_9_loss_7: 2.7632 - dense_9_loss_8: 1.3602 - dense_9_loss_9: 1.8754 - dense_9_loss_10: 2.6455 - dense_9_acc_1: 0.2397 - dense_9_acc_2: 0.5410 - dense_9_acc_3: 0.2496 - dense_9_acc_4: 0.0601 - dense_9_acc_5: 0.8287 - dense_9_acc_6: 0.1021 - dense_9_acc_7: 0.0273 - dense_9_acc_8: 0.7754 - dense_9_acc_9: 0.2033 - dense_9_acc_10: 0.090 - ETA: 35s - loss: 19.2828 - dense_9_loss_1: 1.7464 - dense_9_loss_2: 1.3700 - dense_9_loss_3: 1.9303 - dense_9_loss_4: 2.8335 - dense_9_loss_5: 1.1972 - dense_9_loss_6: 1.5727 - dense_9_loss_7: 2.7649 - dense_9_loss_8: 1.3548 - dense_9_loss_9: 1.8712 - dense_9_loss_10: 2.6419 - dense_9_acc_1: 0.2490 - dense_9_acc_2: 0.5463 - dense_9_acc_3: 0.2521 - dense_9_acc_4: 0.0603 - dense_9_acc_5: 0.8300 - dense_9_acc_6: 0.1063 - dense_9_acc_7: 0.0279 - dense_9_acc_8: 0.7769 - dense_9_acc_9: 0.2051 - dense_9_acc_10: 0.091 - ETA: 33s - loss: 19.2327 - dense_9_loss_1: 1.7325 - dense_9_loss_2: 1.3613 - dense_9_loss_3: 1.9223 - dense_9_loss_4: 2.8315 - dense_9_loss_5: 1.1933 - dense_9_loss_6: 1.5666 - dense_9_loss_7: 2.7648 - dense_9_loss_8: 1.3507 - dense_9_loss_9: 1.8703 - dense_9_loss_10: 2.6393 - dense_9_acc_1: 0.2585 - dense_9_acc_2: 0.5507 - dense_9_acc_3: 0.2551 - dense_9_acc_4: 0.0612 - dense_9_acc_5: 0.8274 - dense_9_acc_6: 0.1126 - dense_9_acc_7: 0.0290 - dense_9_acc_8: 0.7771 - dense_9_acc_9: 0.2054 - dense_9_acc_10: 0.092 - ETA: 32s - loss: 19.1761 - dense_9_loss_1: 1.7177 - dense_9_loss_2: 1.3508 - dense_9_loss_3: 1.9149 - dense_9_loss_4: 2.8289 - dense_9_loss_5: 1.1889 - dense_9_loss_6: 1.5606 - dense_9_loss_7: 2.7627 - dense_9_loss_8: 1.3490 - dense_9_loss_9: 1.8682 - dense_9_loss_10: 2.6343 - dense_9_acc_1: 0.2673 - dense_9_acc_2: 0.5563 - dense_9_acc_3: 0.2574 - dense_9_acc_4: 0.0623 - dense_9_acc_5: 0.8255 - dense_9_acc_6: 0.1199 - dense_9_acc_7: 0.0305 - dense_9_acc_8: 0.7759 - dense_9_acc_9: 0.2086 - dense_9_acc_10: 0.093 - ETA: 31s - loss: 19.1194 - dense_9_loss_1: 1.7028 - dense_9_loss_2: 1.3398 - dense_9_loss_3: 1.9069 - dense_9_loss_4: 2.8285 - dense_9_loss_5: 1.1817 - dense_9_loss_6: 1.5564 - dense_9_loss_7: 2.7642 - dense_9_loss_8: 1.3442 - dense_9_loss_9: 1.8648 - dense_9_loss_10: 2.6301 - dense_9_acc_1: 0.2750 - dense_9_acc_2: 0.5620 - dense_9_acc_3: 0.2593 - dense_9_acc_4: 0.0632 - dense_9_acc_5: 0.8278 - dense_9_acc_6: 0.1199 - dense_9_acc_7: 0.0307 - dense_9_acc_8: 0.7778 - dense_9_acc_9: 0.2112 - dense_9_acc_10: 0.094 - ETA: 29s - loss: 19.0623 - dense_9_loss_1: 1.6878 - dense_9_loss_2: 1.3296 - dense_9_loss_3: 1.8990 - dense_9_loss_4: 2.8271 - dense_9_loss_5: 1.1722 - dense_9_loss_6: 1.5535 - dense_9_loss_7: 2.7661 - dense_9_loss_8: 1.3365 - dense_9_loss_9: 1.8631 - dense_9_loss_10: 2.6273 - dense_9_acc_1: 0.2824 - dense_9_acc_2: 0.5667 - dense_9_acc_3: 0.2612 - dense_9_acc_4: 0.0643 - dense_9_acc_5: 0.8301 - dense_9_acc_6: 0.1199 - dense_9_acc_7: 0.0313 - dense_9_acc_8: 0.7799 - dense_9_acc_9: 0.2125 - dense_9_acc_10: 0.095 - ETA: 28s - loss: 19.0066 - dense_9_loss_1: 1.6735 - dense_9_loss_2: 1.3205 - dense_9_loss_3: 1.8937 - dense_9_loss_4: 2.8244 - dense_9_loss_5: 1.1627 - dense_9_loss_6: 1.5502 - dense_9_loss_7: 2.7673 - dense_9_loss_8: 1.3300 - dense_9_loss_9: 1.8605 - dense_9_loss_10: 2.6238 - dense_9_acc_1: 0.2889 - dense_9_acc_2: 0.5707 - dense_9_acc_3: 0.2620 - dense_9_acc_4: 0.0646 - dense_9_acc_5: 0.8324 - dense_9_acc_6: 0.1203 - dense_9_acc_7: 0.0316 - dense_9_acc_8: 0.7822 - dense_9_acc_9: 0.2157 - dense_9_acc_10: 0.095 - ETA: 26s - loss: 18.9502 - dense_9_loss_1: 1.6593 - dense_9_loss_2: 1.3105 - dense_9_loss_3: 1.8873 - dense_9_loss_4: 2.8227 - dense_9_loss_5: 1.1540 - dense_9_loss_6: 1.5458 - dense_9_loss_7: 2.7696 - dense_9_loss_8: 1.3246 - dense_9_loss_9: 1.8584 - dense_9_loss_10: 2.6180 - dense_9_acc_1: 0.2964 - dense_9_acc_2: 0.5752 - dense_9_acc_3: 0.2635 - dense_9_acc_4: 0.0647 - dense_9_acc_5: 0.8345 - dense_9_acc_6: 0.1227 - dense_9_acc_7: 0.0314 - dense_9_acc_8: 0.7843 - dense_9_acc_9: 0.2186 - dense_9_acc_10: 0.097 - ETA: 25s - loss: 18.8904 - dense_9_loss_1: 1.6451 - dense_9_loss_2: 1.3005 - dense_9_loss_3: 1.8809 - dense_9_loss_4: 2.8197 - dense_9_loss_5: 1.1461 - dense_9_loss_6: 1.5403 - dense_9_loss_7: 2.7692 - dense_9_loss_8: 1.3187 - dense_9_loss_9: 1.8566 - dense_9_loss_10: 2.6134 - dense_9_acc_1: 0.3041 - dense_9_acc_2: 0.5799 - dense_9_acc_3: 0.2646 - dense_9_acc_4: 0.0650 - dense_9_acc_5: 0.8367 - dense_9_acc_6: 0.1285 - dense_9_acc_7: 0.0315 - dense_9_acc_8: 0.7864 - dense_9_acc_9: 0.2192 - dense_9_acc_10: 0.098 - ETA: 24s - loss: 18.8313 - dense_9_loss_1: 1.6309 - dense_9_loss_2: 1.2901 - dense_9_loss_3: 1.8736 - dense_9_loss_4: 2.8171 - dense_9_loss_5: 1.1386 - dense_9_loss_6: 1.5323 - dense_9_loss_7: 2.7719 - dense_9_loss_8: 1.3129 - dense_9_loss_9: 1.8541 - dense_9_loss_10: 2.6098 - dense_9_acc_1: 0.3118 - dense_9_acc_2: 0.5843 - dense_9_acc_3: 0.2661 - dense_9_acc_4: 0.0657 - dense_9_acc_5: 0.8387 - dense_9_acc_6: 0.1377 - dense_9_acc_7: 0.0318 - dense_9_acc_8: 0.7889 - dense_9_acc_9: 0.2196 - dense_9_acc_10: 0.099 - ETA: 23s - loss: 18.7735 - dense_9_loss_1: 1.6173 - dense_9_loss_2: 1.2800 - dense_9_loss_3: 1.8659 - dense_9_loss_4: 2.8141 - dense_9_loss_5: 1.1323 - dense_9_loss_6: 1.5248 - dense_9_loss_7: 2.7729 - dense_9_loss_8: 1.3088 - dense_9_loss_9: 1.8519 - dense_9_loss_10: 2.6056 - dense_9_acc_1: 0.3200 - dense_9_acc_2: 0.5890 - dense_9_acc_3: 0.2684 - dense_9_acc_4: 0.0660 - dense_9_acc_5: 0.8408 - dense_9_acc_6: 0.1462 - dense_9_acc_7: 0.0324 - dense_9_acc_8: 0.7910 - dense_9_acc_9: 0.2231 - dense_9_acc_10: 0.1010"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9600/10000 [===========================>..] - ETA: 21s - loss: 18.7120 - dense_9_loss_1: 1.6033 - dense_9_loss_2: 1.2701 - dense_9_loss_3: 1.8586 - dense_9_loss_4: 2.8112 - dense_9_loss_5: 1.1256 - dense_9_loss_6: 1.5172 - dense_9_loss_7: 2.7721 - dense_9_loss_8: 1.3048 - dense_9_loss_9: 1.8477 - dense_9_loss_10: 2.6013 - dense_9_acc_1: 0.3279 - dense_9_acc_2: 0.5935 - dense_9_acc_3: 0.2701 - dense_9_acc_4: 0.0658 - dense_9_acc_5: 0.8427 - dense_9_acc_6: 0.1541 - dense_9_acc_7: 0.0326 - dense_9_acc_8: 0.7920 - dense_9_acc_9: 0.2275 - dense_9_acc_10: 0.102 - ETA: 20s - loss: 18.6459 - dense_9_loss_1: 1.5892 - dense_9_loss_2: 1.2595 - dense_9_loss_3: 1.8509 - dense_9_loss_4: 2.8082 - dense_9_loss_5: 1.1178 - dense_9_loss_6: 1.5084 - dense_9_loss_7: 2.7721 - dense_9_loss_8: 1.2982 - dense_9_loss_9: 1.8439 - dense_9_loss_10: 2.5978 - dense_9_acc_1: 0.3360 - dense_9_acc_2: 0.5983 - dense_9_acc_3: 0.2728 - dense_9_acc_4: 0.0665 - dense_9_acc_5: 0.8446 - dense_9_acc_6: 0.1633 - dense_9_acc_7: 0.0332 - dense_9_acc_8: 0.7939 - dense_9_acc_9: 0.2311 - dense_9_acc_10: 0.102 - ETA: 19s - loss: 18.5817 - dense_9_loss_1: 1.5752 - dense_9_loss_2: 1.2491 - dense_9_loss_3: 1.8448 - dense_9_loss_4: 2.8044 - dense_9_loss_5: 1.1094 - dense_9_loss_6: 1.4998 - dense_9_loss_7: 2.7737 - dense_9_loss_8: 1.2910 - dense_9_loss_9: 1.8408 - dense_9_loss_10: 2.5936 - dense_9_acc_1: 0.3435 - dense_9_acc_2: 0.6028 - dense_9_acc_3: 0.2743 - dense_9_acc_4: 0.0671 - dense_9_acc_5: 0.8465 - dense_9_acc_6: 0.1718 - dense_9_acc_7: 0.0337 - dense_9_acc_8: 0.7961 - dense_9_acc_9: 0.2330 - dense_9_acc_10: 0.103 - ETA: 17s - loss: 18.5206 - dense_9_loss_1: 1.5616 - dense_9_loss_2: 1.2392 - dense_9_loss_3: 1.8393 - dense_9_loss_4: 2.8006 - dense_9_loss_5: 1.1007 - dense_9_loss_6: 1.4917 - dense_9_loss_7: 2.7761 - dense_9_loss_8: 1.2833 - dense_9_loss_9: 1.8380 - dense_9_loss_10: 2.5900 - dense_9_acc_1: 0.3506 - dense_9_acc_2: 0.6069 - dense_9_acc_3: 0.2754 - dense_9_acc_4: 0.0680 - dense_9_acc_5: 0.8483 - dense_9_acc_6: 0.1805 - dense_9_acc_7: 0.0339 - dense_9_acc_8: 0.7986 - dense_9_acc_9: 0.2351 - dense_9_acc_10: 0.103 - ETA: 16s - loss: 18.4547 - dense_9_loss_1: 1.5482 - dense_9_loss_2: 1.2294 - dense_9_loss_3: 1.8323 - dense_9_loss_4: 2.7978 - dense_9_loss_5: 1.0917 - dense_9_loss_6: 1.4841 - dense_9_loss_7: 2.7754 - dense_9_loss_8: 1.2757 - dense_9_loss_9: 1.8347 - dense_9_loss_10: 2.5853 - dense_9_acc_1: 0.3573 - dense_9_acc_2: 0.6109 - dense_9_acc_3: 0.2772 - dense_9_acc_4: 0.0682 - dense_9_acc_5: 0.8501 - dense_9_acc_6: 0.1887 - dense_9_acc_7: 0.0341 - dense_9_acc_8: 0.8009 - dense_9_acc_9: 0.2388 - dense_9_acc_10: 0.104 - ETA: 15s - loss: 18.3868 - dense_9_loss_1: 1.5347 - dense_9_loss_2: 1.2198 - dense_9_loss_3: 1.8261 - dense_9_loss_4: 2.7937 - dense_9_loss_5: 1.0826 - dense_9_loss_6: 1.4767 - dense_9_loss_7: 2.7748 - dense_9_loss_8: 1.2668 - dense_9_loss_9: 1.8308 - dense_9_loss_10: 2.5808 - dense_9_acc_1: 0.3640 - dense_9_acc_2: 0.6149 - dense_9_acc_3: 0.2790 - dense_9_acc_4: 0.0688 - dense_9_acc_5: 0.8519 - dense_9_acc_6: 0.1959 - dense_9_acc_7: 0.0344 - dense_9_acc_8: 0.8031 - dense_9_acc_9: 0.2421 - dense_9_acc_10: 0.105 - ETA: 14s - loss: 18.3194 - dense_9_loss_1: 1.5211 - dense_9_loss_2: 1.2098 - dense_9_loss_3: 1.8199 - dense_9_loss_4: 2.7910 - dense_9_loss_5: 1.0736 - dense_9_loss_6: 1.4681 - dense_9_loss_7: 2.7741 - dense_9_loss_8: 1.2569 - dense_9_loss_9: 1.8268 - dense_9_loss_10: 2.5782 - dense_9_acc_1: 0.3707 - dense_9_acc_2: 0.6187 - dense_9_acc_3: 0.2803 - dense_9_acc_4: 0.0690 - dense_9_acc_5: 0.8536 - dense_9_acc_6: 0.2039 - dense_9_acc_7: 0.0345 - dense_9_acc_8: 0.8054 - dense_9_acc_9: 0.2449 - dense_9_acc_10: 0.105 - ETA: 13s - loss: 18.2488 - dense_9_loss_1: 1.5083 - dense_9_loss_2: 1.2005 - dense_9_loss_3: 1.8140 - dense_9_loss_4: 2.7869 - dense_9_loss_5: 1.0654 - dense_9_loss_6: 1.4590 - dense_9_loss_7: 2.7715 - dense_9_loss_8: 1.2475 - dense_9_loss_9: 1.8213 - dense_9_loss_10: 2.5744 - dense_9_acc_1: 0.3767 - dense_9_acc_2: 0.6225 - dense_9_acc_3: 0.2810 - dense_9_acc_4: 0.0693 - dense_9_acc_5: 0.8552 - dense_9_acc_6: 0.2119 - dense_9_acc_7: 0.0351 - dense_9_acc_8: 0.8076 - dense_9_acc_9: 0.2492 - dense_9_acc_10: 0.106 - ETA: 11s - loss: 18.1812 - dense_9_loss_1: 1.4958 - dense_9_loss_2: 1.1909 - dense_9_loss_3: 1.8074 - dense_9_loss_4: 2.7835 - dense_9_loss_5: 1.0578 - dense_9_loss_6: 1.4500 - dense_9_loss_7: 2.7677 - dense_9_loss_8: 1.2402 - dense_9_loss_9: 1.8175 - dense_9_loss_10: 2.5704 - dense_9_acc_1: 0.3833 - dense_9_acc_2: 0.6264 - dense_9_acc_3: 0.2826 - dense_9_acc_4: 0.0699 - dense_9_acc_5: 0.8569 - dense_9_acc_6: 0.2192 - dense_9_acc_7: 0.0364 - dense_9_acc_8: 0.8098 - dense_9_acc_9: 0.2519 - dense_9_acc_10: 0.107 - ETA: 10s - loss: 18.1121 - dense_9_loss_1: 1.4831 - dense_9_loss_2: 1.1816 - dense_9_loss_3: 1.8012 - dense_9_loss_4: 2.7793 - dense_9_loss_5: 1.0501 - dense_9_loss_6: 1.4406 - dense_9_loss_7: 2.7642 - dense_9_loss_8: 1.2317 - dense_9_loss_9: 1.8129 - dense_9_loss_10: 2.5674 - dense_9_acc_1: 0.3896 - dense_9_acc_2: 0.6299 - dense_9_acc_3: 0.2837 - dense_9_acc_4: 0.0703 - dense_9_acc_5: 0.8584 - dense_9_acc_6: 0.2269 - dense_9_acc_7: 0.0373 - dense_9_acc_8: 0.8118 - dense_9_acc_9: 0.2544 - dense_9_acc_10: 0.108 - ETA: 9s - loss: 18.0386 - dense_9_loss_1: 1.4703 - dense_9_loss_2: 1.1721 - dense_9_loss_3: 1.7944 - dense_9_loss_4: 2.7753 - dense_9_loss_5: 1.0422 - dense_9_loss_6: 1.4321 - dense_9_loss_7: 2.7603 - dense_9_loss_8: 1.2219 - dense_9_loss_9: 1.8073 - dense_9_loss_10: 2.5626 - dense_9_acc_1: 0.3960 - dense_9_acc_2: 0.6336 - dense_9_acc_3: 0.2855 - dense_9_acc_4: 0.0709 - dense_9_acc_5: 0.8600 - dense_9_acc_6: 0.2337 - dense_9_acc_7: 0.0382 - dense_9_acc_8: 0.8138 - dense_9_acc_9: 0.2574 - dense_9_acc_10: 0.109 - ETA: 8s - loss: 17.9650 - dense_9_loss_1: 1.4581 - dense_9_loss_2: 1.1626 - dense_9_loss_3: 1.7874 - dense_9_loss_4: 2.7722 - dense_9_loss_5: 1.0342 - dense_9_loss_6: 1.4227 - dense_9_loss_7: 2.7567 - dense_9_loss_8: 1.2116 - dense_9_loss_9: 1.8021 - dense_9_loss_10: 2.5576 - dense_9_acc_1: 0.4024 - dense_9_acc_2: 0.6374 - dense_9_acc_3: 0.2872 - dense_9_acc_4: 0.0708 - dense_9_acc_5: 0.8615 - dense_9_acc_6: 0.2411 - dense_9_acc_7: 0.0389 - dense_9_acc_8: 0.8159 - dense_9_acc_9: 0.2608 - dense_9_acc_10: 0.11 - ETA: 7s - loss: 17.8963 - dense_9_loss_1: 1.4465 - dense_9_loss_2: 1.1538 - dense_9_loss_3: 1.7816 - dense_9_loss_4: 2.7689 - dense_9_loss_5: 1.0258 - dense_9_loss_6: 1.4136 - dense_9_loss_7: 2.7537 - dense_9_loss_8: 1.2007 - dense_9_loss_9: 1.7976 - dense_9_loss_10: 2.5540 - dense_9_acc_1: 0.4084 - dense_9_acc_2: 0.6409 - dense_9_acc_3: 0.2880 - dense_9_acc_4: 0.0710 - dense_9_acc_5: 0.8630 - dense_9_acc_6: 0.2482 - dense_9_acc_7: 0.0398 - dense_9_acc_8: 0.8178 - dense_9_acc_9: 0.2633 - dense_9_acc_10: 0.11 - ETA: 6s - loss: 17.8252 - dense_9_loss_1: 1.4353 - dense_9_loss_2: 1.1461 - dense_9_loss_3: 1.7773 - dense_9_loss_4: 2.7658 - dense_9_loss_5: 1.0172 - dense_9_loss_6: 1.4049 - dense_9_loss_7: 2.7484 - dense_9_loss_8: 1.1897 - dense_9_loss_9: 1.7909 - dense_9_loss_10: 2.5496 - dense_9_acc_1: 0.4136 - dense_9_acc_2: 0.6436 - dense_9_acc_3: 0.2880 - dense_9_acc_4: 0.0713 - dense_9_acc_5: 0.8645 - dense_9_acc_6: 0.2547 - dense_9_acc_7: 0.0405 - dense_9_acc_8: 0.8198 - dense_9_acc_9: 0.2678 - dense_9_acc_10: 0.11 - ETA: 5s - loss: 17.7520 - dense_9_loss_1: 1.4233 - dense_9_loss_2: 1.1369 - dense_9_loss_3: 1.7711 - dense_9_loss_4: 2.7624 - dense_9_loss_5: 1.0086 - dense_9_loss_6: 1.3964 - dense_9_loss_7: 2.7434 - dense_9_loss_8: 1.1788 - dense_9_loss_9: 1.7856 - dense_9_loss_10: 2.5454 - dense_9_acc_1: 0.4195 - dense_9_acc_2: 0.6471 - dense_9_acc_3: 0.2889 - dense_9_acc_4: 0.0718 - dense_9_acc_5: 0.8659 - dense_9_acc_6: 0.2614 - dense_9_acc_7: 0.0412 - dense_9_acc_8: 0.8217 - dense_9_acc_9: 0.2700 - dense_9_acc_10: 0.11 - ETA: 4s - loss: 17.6789 - dense_9_loss_1: 1.4119 - dense_9_loss_2: 1.1282 - dense_9_loss_3: 1.7645 - dense_9_loss_4: 2.7577 - dense_9_loss_5: 1.0000 - dense_9_loss_6: 1.3880 - dense_9_loss_7: 2.7393 - dense_9_loss_8: 1.1678 - dense_9_loss_9: 1.7796 - dense_9_loss_10: 2.5420 - dense_9_acc_1: 0.4250 - dense_9_acc_2: 0.6502 - dense_9_acc_3: 0.2907 - dense_9_acc_4: 0.0725 - dense_9_acc_5: 0.8673 - dense_9_acc_6: 0.2678 - dense_9_acc_7: 0.0416 - dense_9_acc_8: 0.8235 - dense_9_acc_9: 0.2733 - dense_9_acc_10: 0.1139"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 3s - loss: 17.6050 - dense_9_loss_1: 1.4003 - dense_9_loss_2: 1.1192 - dense_9_loss_3: 1.7589 - dense_9_loss_4: 2.7530 - dense_9_loss_5: 0.9915 - dense_9_loss_6: 1.3803 - dense_9_loss_7: 2.7331 - dense_9_loss_8: 1.1570 - dense_9_loss_9: 1.7733 - dense_9_loss_10: 2.5383 - dense_9_acc_1: 0.4308 - dense_9_acc_2: 0.6537 - dense_9_acc_3: 0.2913 - dense_9_acc_4: 0.0733 - dense_9_acc_5: 0.8687 - dense_9_acc_6: 0.2734 - dense_9_acc_7: 0.0432 - dense_9_acc_8: 0.8254 - dense_9_acc_9: 0.2764 - dense_9_acc_10: 0.11 - ETA: 2s - loss: 17.5308 - dense_9_loss_1: 1.3891 - dense_9_loss_2: 1.1104 - dense_9_loss_3: 1.7529 - dense_9_loss_4: 2.7501 - dense_9_loss_5: 0.9831 - dense_9_loss_6: 1.3716 - dense_9_loss_7: 2.7276 - dense_9_loss_8: 1.1468 - dense_9_loss_9: 1.7660 - dense_9_loss_10: 2.5331 - dense_9_acc_1: 0.4364 - dense_9_acc_2: 0.6570 - dense_9_acc_3: 0.2927 - dense_9_acc_4: 0.0735 - dense_9_acc_5: 0.8700 - dense_9_acc_6: 0.2797 - dense_9_acc_7: 0.0451 - dense_9_acc_8: 0.8271 - dense_9_acc_9: 0.2804 - dense_9_acc_10: 0.11 - ETA: 1s - loss: 17.4582 - dense_9_loss_1: 1.3781 - dense_9_loss_2: 1.1019 - dense_9_loss_3: 1.7475 - dense_9_loss_4: 2.7465 - dense_9_loss_5: 0.9748 - dense_9_loss_6: 1.3626 - dense_9_loss_7: 2.7220 - dense_9_loss_8: 1.1366 - dense_9_loss_9: 1.7595 - dense_9_loss_10: 2.5288 - dense_9_acc_1: 0.4418 - dense_9_acc_2: 0.6602 - dense_9_acc_3: 0.2938 - dense_9_acc_4: 0.0736 - dense_9_acc_5: 0.8713 - dense_9_acc_6: 0.2860 - dense_9_acc_7: 0.0466 - dense_9_acc_8: 0.8289 - dense_9_acc_9: 0.2835 - dense_9_acc_10: 0.11 - 102s 10ms/step - loss: 17.3851 - dense_9_loss_1: 1.3672 - dense_9_loss_2: 1.0935 - dense_9_loss_3: 1.7420 - dense_9_loss_4: 2.7423 - dense_9_loss_5: 0.9665 - dense_9_loss_6: 1.3537 - dense_9_loss_7: 2.7161 - dense_9_loss_8: 1.1265 - dense_9_loss_9: 1.7527 - dense_9_loss_10: 2.5246 - dense_9_acc_1: 0.4470 - dense_9_acc_2: 0.6631 - dense_9_acc_3: 0.2946 - dense_9_acc_4: 0.0745 - dense_9_acc_5: 0.8726 - dense_9_acc_6: 0.2920 - dense_9_acc_7: 0.0479 - dense_9_acc_8: 0.8306 - dense_9_acc_9: 0.2866 - dense_9_acc_10: 0.1186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21fdf844dd8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Adam(lr = 0.005, beta_1 = 0.9, beta_2 = 0.999, decay = 0.01)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer =opt, metrics = ['accuracy'] )\n",
    "\n",
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))\n",
    "\n",
    "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 May 1979\n",
      "output: 1979-05-03\n",
      "source: 5 April 09\n",
      "output: 2009-05-05\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09\n",
      "source: March 3 2001\n",
      "output: 2001-03-03\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model/model.h5')\n",
    "\n",
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "for example in EXAMPLES:\n",
    "    \n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))\n",
    "    source = np.reshape(source, (1, source.shape[0], source.shape[1]))\n",
    "    prediction = model.predict([source, s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2201abfee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAGsCAYAAAD9ro91AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk7UkSYUzWUuSVDiTtSRJhfv/LXokBWl82BoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2201abf7470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
